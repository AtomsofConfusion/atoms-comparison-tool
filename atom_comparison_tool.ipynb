{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f32117",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "codeQL_directory = \"./codeQL_data\"\n",
    "clojure_directory = \"./clojure_data\"\n",
    "coccinelle_directory = \"./coccinelle_data\"\n",
    "dataframes = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a7fa8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CodeQL .sarif files and store them in dataframes dictionary\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "for filename in os.listdir(codeQL_directory):\n",
    "    if filename.endswith('.sarif'):\n",
    "        file_path = os.path.join(codeQL_directory, filename)\n",
    "        dataframe_key = filename[:-6]\n",
    "        pt = Path(file_path)\n",
    "        file_content = pt.read_text()\n",
    "        json_value = json.loads(file_content)\n",
    "        p = pd.DataFrame(columns = [\"Type\", \"File\", \"Line\", \"CQL\", \"CQL_Column\", \"CQL_CodeQL\"])\n",
    "        rows = []\n",
    "    print(\"Loading:\", filename)\n",
    "    # These are the index paths of the data we are looking for. Each is located inside nested dictionaries.\n",
    "    for i in range(len(json_value[\"runs\"][0][\"results\"])):\n",
    "        s = pd.Series({\n",
    "            \"Type\": filename[:-6],\n",
    "            \"File\": json_value[\"runs\"][0][\"results\"][i][\"locations\"][0][\"physicalLocation\"][\"artifactLocation\"][\"uri\"], \n",
    "            \"Line\": json_value[\"runs\"][0][\"results\"][i][\"locations\"][0][\"physicalLocation\"][\"region\"][\"startLine\"],\n",
    "            \"CQL\": '+',\n",
    "            \"CQL_Column\": json_value[\"runs\"][0][\"results\"][i][\"locations\"][0][\"physicalLocation\"][\"region\"].get(\"startColumn\", None),\n",
    "            \"CQL_Code\": json_value[\"runs\"][0][\"results\"][i][\"locations\"][0][\"physicalLocation\"][\"contextRegion\"][\"snippet\"][\"text\"].splitlines()[2:-2],\n",
    "        })\n",
    "        rows.append(s)\n",
    "    p = pd.concat(rows, axis=1).T\n",
    "    \n",
    "    # These lines convert these columns to string format\n",
    "    p[\"CQL_Code\"] = p[\"CQL_Code\"].apply(lambda x: '\\n'.join(x) if isinstance(x, list) else x)\n",
    "    p[\"File\"] = p[\"File\"].apply(lambda x: '\\n'.join(x) if isinstance(x, list) else x)\n",
    "    p[\"File\"] = p[\"File\"].str.split('/').str[-1]\n",
    "    dataframes[dataframe_key] = p\n",
    "    \n",
    "print(\"DataFrame Names:\", dataframes.keys())\n",
    "# for i in dataframes.values():\n",
    "#     display(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a66391e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Clojure dataset\n",
    "\n",
    "clojure_master = pd.read_csv(\"./clojure_data/atomsClojure.csv\")\n",
    "# Get only the filename, removing the path\n",
    "clojure_master['file'] = clojure_master['file'].str.split('/').str[-1]\n",
    "# display(clojure_master)\n",
    "print(\"Clojure Types:\", clojure_master[\"atom\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc40821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Clojure dataset for merge\n",
    "\n",
    "name_mapping = {\n",
    "    'pre-increment': 'preIncr',\n",
    "    'operator-precedence': 'operator_precedence',\n",
    "    'conditional': 'conditional',\n",
    "    'preprocessor-in-statement': 'preprocessor_in_statement',\n",
    "    'logic-as-control-flow': 'logic_as_control_flow',\n",
    "    'type-conversion': 'type_conversion',\n",
    "    'comma-operator': 'comma_atoms',\n",
    "    'implicit-predicate': 'implicit_predicate',\n",
    "    'post-increment': 'postIncr',\n",
    "    'assignment-as-value': 'assignment_as_value',\n",
    "    'repurposed-variable': 'repurposed_variable',\n",
    "    'omitted-curly-braces' : 'omitted_curly_braces',\n",
    "    'macro-operator-precedence' : 'macro_operator_precedence',\n",
    "    'literal-encoding' : 'literal_encoding'\n",
    "}\n",
    "\n",
    "clojure_master['atom'] = clojure_master['atom'].map(name_mapping)\n",
    "clojure_master.rename(columns = {\n",
    "    'atom': 'Type',\n",
    "    'file': 'File',\n",
    "    'line': 'Line',\n",
    "    'code': 'CLJ_Code'\n",
    "}, inplace=True)\n",
    "\n",
    "clojure_master[\"CLJ\"] = '+'\n",
    "\n",
    "clojure_master.drop(columns = ['offset'], inplace = True)\n",
    "# display(clojure_master)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466cc440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge Clojure and CodeQL dataframes\n",
    "\n",
    "for key, df in dataframes.items():\n",
    "    k = pd.merge(clojure_master[clojure_master[\"Type\"] == key], df, on = ['File', 'Type', 'Line'], how = 'outer')\n",
    "    k = k[[\"Type\", \"File\", \"Line\", \"CLJ\", \"CQL\", \"CLJ_Code\", \"CQL_Column\", \"CQL_Code\"]]\n",
    "    k = k.drop_duplicates(subset = [\"Type\", \"File\", \"Line\", \"CLJ\", \"CQL\"], keep = 'first')\n",
    "    k['CLJ'] = k['CLJ'].fillna('-')\n",
    "    k['CQL'] = k['CQL'].fillna('-')\n",
    "    dataframes[key] = k.sort_values(by = [\"File\", \"Line\"]).reset_index().drop(\"index\", axis = 1)\n",
    "    print(f\"Merged DataFrame for {key}:\")\n",
    "#     display(dataframes[key].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c08e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Coccinelle dataframes\n",
    "\n",
    "coccinelle_dataframes = {}\n",
    "for filename in os.listdir(coccinelle_directory):\n",
    "    if filename.endswith('.csv'):\n",
    "        file_path = os.path.join(coccinelle_directory, filename)\n",
    "        dataframe_key = filename[:-4]\n",
    "        p = pd.read_csv(file_path)\n",
    "        p.columns = [\"Type\", \"File\", \"Line\", \"CNL_Column\", \"CNL_Code\"]\n",
    "        p[\"File\"] = p[\"File\"].str.split('/').str[-1]\n",
    "        p[\"CNL\"] = '+'\n",
    "        coccinelle_dataframes[dataframe_key] = p\n",
    "print(coccinelle_dataframes.keys())\n",
    "\n",
    "coccinelle_mapping = {\n",
    "    'post-increment': 'postIncr',\n",
    "    'assignment-as-value': 'assignment_as_value',\n",
    "    'conditional' : 'conditional',\n",
    "    'pre-increment': 'preIncr',\n",
    "    'comma-operator': 'comma_atoms',\n",
    "}\n",
    "\n",
    "\n",
    "for i in coccinelle_dataframes.values():\n",
    "    i['Type'] = i['Type'].map(coccinelle_mapping)\n",
    "#     display(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418e1cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge Coccinelle DataFrames\n",
    "\n",
    "for i in coccinelle_dataframes.values():\n",
    "    key = i.loc[0, \"Type\"]\n",
    "    toMerge = dataframes[key]\n",
    "    k = pd.merge(toMerge, i, on = ['File', 'Type', 'Line'], how = 'outer')\n",
    "    k['CLJ'] = k['CLJ'].fillna('-')\n",
    "    k['CQL'] = k['CQL'].fillna('-')\n",
    "    k['CNL'] = k['CNL'].fillna('-')\n",
    "    # Reordering columns\n",
    "    k = k[[\"Type\", \"File\", \"Line\", \"CLJ\", \"CQL\", \"CNL\", \"CLJ_Code\", \"CQL_Column\", \"CQL_Code\", \"CNL_Column\", \"CNL_Code\"]]\n",
    "    k = k.drop_duplicates(subset = [\"Type\", \"File\", \"Line\", \"CLJ\", \"CQL\", \"CNL\"], keep = 'first')\n",
    "    # Float type For consistency with CQL_Column, which is forced as a float because of NaN values\n",
    "    k[\"CQL_Column\"] = k[\"CQL_Column\"].astype(float)\n",
    "    dataframes[key] = k.sort_values(by = [\"File\", \"Line\"]).reset_index().drop(\"index\", axis = 1)\n",
    "    print(f\"Merged DataFrame for {key}:\")\n",
    "#     display(dataframes[key].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2ba2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output merged CSVs to output_directory\n",
    "\n",
    "output_directory = 'output'\n",
    "\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "for key, df in dataframes.items():\n",
    "    file_name = f'{key}_comparison.csv'\n",
    "    path = os.path.join(output_directory, file_name)\n",
    "    df.to_csv(path, index = False)\n",
    "    print(f\"DataFrame '{key}' has been saved to {file_name}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932c2b27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
